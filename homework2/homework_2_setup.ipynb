{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70225573-6a63-47b5-9e4e-3311014fe228",
   "metadata": {},
   "source": [
    "# 1. PCA for Network Intrusion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05100ad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T13:44:11.395800Z",
     "start_time": "2025-05-27T13:44:11.389617Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_kdd_data(data_dir=\"./datasets/kdd_balanced\"):\n",
    "    \"\"\"\n",
    "    Load the balanced dataset from Parquet format (ultra-fast loading).\n",
    "    \n",
    "    Returns:\n",
    "        D_balanced: Feature matrix (numpy array)\n",
    "        is_normal_balanced: Boolean labels (numpy array)  \n",
    "        original_indices: Original indices from full dataset (numpy array)\n",
    "        df_balanced: Original dataframe subset (if available)\n",
    "        metadata: Dataset metadata\n",
    "    \"\"\"\n",
    "    from pathlib import Path\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    \n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    # Check if required files exist\n",
    "    required_files = [\"balanced_dataset.parquet\", \"metadata.json\"]\n",
    "    missing_files = [f for f in required_files if not (data_path / f).exists()]\n",
    "    if missing_files:\n",
    "        raise FileNotFoundError(f\"Required files not found in {data_path}: {missing_files}\")\n",
    "    \n",
    "    # Load main dataset (this is very fast with Parquet)\n",
    "    df_main = pd.read_parquet(data_path / \"balanced_dataset.parquet\")\n",
    "    \n",
    "    # Extract components\n",
    "    feature_cols = [col for col in df_main.columns if col.startswith('feature_')]\n",
    "    D_balanced = df_main[feature_cols].values\n",
    "    is_normal_balanced = df_main['is_normal'].values\n",
    "    original_indices = df_main['original_index'].values\n",
    "    \n",
    "    # Load original dataframe if available\n",
    "    df_balanced = None\n",
    "    if (data_path / \"original_data_balanced.parquet\").exists():\n",
    "        df_balanced = pd.read_parquet(data_path / \"original_data_balanced.parquet\")\n",
    "    \n",
    "    # Load metadata\n",
    "    with open(data_path / \"metadata.json\", 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(f\"Balanced dataset loaded from {data_path} (Parquet format)\")\n",
    "    print(f\"  Features: {D_balanced.shape}\")\n",
    "    print(f\"  Normal: {metadata['n_normal']:,}, Intrusion: {metadata['n_intrusion']:,}\")\n",
    "    \n",
    "    return D_balanced, is_normal_balanced, original_indices, df_balanced, metadata\n",
    "\n",
    "def compute_pca_from_intrusion_data(D_intrusion, r):\n",
    "    \"\"\"\n",
    "    Compute PCA using SVD on intrusion data with rank r.\n",
    "    \n",
    "    Key insight: We train PCA on INTRUSION data, so normal data\n",
    "    will have higher reconstruction error in this learned space.\n",
    "    \n",
    "    Returns:\n",
    "        X: Principal components (learned from intrusion data)\n",
    "        mu_intrusion: Mean vector of intrusion data\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def project_to_low_dimensional_space(D, X, mu_intrusion):\n",
    "    \"\"\"\n",
    "    Project any data points into the low-dimensional space defined by\n",
    "    intrusion-trained PCA components.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def reconstruct_from_low_dimensional(Y, X, mu_intrusion):\n",
    "    \"\"\"Reconstruct data points from low-dimensional coordinates.\"\"\"\n",
    "\n",
    "\n",
    "def compute_reconstruction_error(original, reconstructed):\n",
    "    \"\"\"Compute L2 reconstruction error.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65fa2795e898f5d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T13:44:18.586799Z",
     "start_time": "2025-05-27T13:44:11.405201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset loaded from datasets\\kdd_balanced (Parquet format)\n",
      "  Features: (97378, 118)\n",
      "  Normal: 97,278, Intrusion: 100\n",
      "First three coordinates of the 8th data point (low-dimensional representation):\n",
      "[-0.09908221 -0.99311985 -0.06296968]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the full dataset\n",
    "D, is_normal, original_indices, df_balanced, metadata = load_kdd_data()\n",
    "\n",
    "# Step 2: Compute mean vector of full dataset\n",
    "mu = D.mean(axis=0)\n",
    "\n",
    "# Step 3: Center the dataset\n",
    "C = D - mu\n",
    "\n",
    "# Step 4: Apply PCA (Truncated SVD) with rank r=10\n",
    "r = 10\n",
    "svd = TruncatedSVD(n_components=r)\n",
    "Y = svd.fit_transform(C)  # Low-dimensional representations of all data points\n",
    "X = svd.components_.T     # Principal components\n",
    "\n",
    "# Step 5: Get the low-dimensional representation of the 8th data point (index 7)\n",
    "y8 = Y[7]\n",
    "\n",
    "# Step 6: Report first three coordinates\n",
    "print(\"First three coordinates of the 8th data point (low-dimensional representation):\")\n",
    "print(y8[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa5d4c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset loaded from datasets\\kdd_balanced (Parquet format)\n",
      "  Features: (97378, 118)\n",
      "  Normal: 97,278, Intrusion: 100\n",
      "Reconstruction error of 8th data point: 3.5494\n",
      "Mean reconstruction error (intrusion): 30.1167\n",
      "Mean reconstruction error (normal): 12.8758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load data\n",
    "D, is_normal, original_indices, df_balanced, metadata = load_kdd_data()\n",
    "\n",
    "# Step 2: Compute mean and center data\n",
    "mu = D.mean(axis=0)\n",
    "C = D - mu\n",
    "\n",
    "# Step 3: Train PCA (rank 10)\n",
    "r = 10\n",
    "svd = TruncatedSVD(n_components=r)\n",
    "Y = svd.fit_transform(C)\n",
    "X = svd.components_.T  # shape (n_features, r)\n",
    "\n",
    "# Step 4: Reconstruct all points\n",
    "C_hat = Y @ X.T       # low-rank approximation in centered space\n",
    "D_hat = C_hat + mu    # add mean back to get reconstructed points\n",
    "\n",
    "# Step 5: Compute reconstruction error for each point\n",
    "reconstruction_errors = np.sum((D - D_hat)**2, axis=1)\n",
    "\n",
    "# Step 6: Get required values\n",
    "error_8 = reconstruction_errors[7]\n",
    "mean_error_intrusion = np.mean(reconstruction_errors[~is_normal])\n",
    "mean_error_normal = np.mean(reconstruction_errors[is_normal])\n",
    "\n",
    "# Step 7: Report\n",
    "print(f\"Reconstruction error of 8th data point: {error_8:.4f}\")\n",
    "print(f\"Mean reconstruction error (intrusion): {mean_error_intrusion:.4f}\")\n",
    "print(f\"Mean reconstruction error (normal): {mean_error_normal:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c131b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 90th percentile threshold:\n",
      "  tp_90 = 99\n",
      "  fp_90 = 9639\n",
      "For 95th percentile threshold:\n",
      "  tp_95 = 38\n",
      "  fp_95 = 4831\n",
      "For 99th percentile threshold:\n",
      "  tp_99 = 2\n",
      "  fp_99 = 972\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Assumes you already computed reconstruction_errors and is_normal as before ---\n",
    "\n",
    "# Step 1: Compute percentiles\n",
    "percentiles = [90, 95, 99]\n",
    "thresholds = np.percentile(reconstruction_errors, percentiles)\n",
    "\n",
    "# Step 2: For each threshold, compute TP and FP\n",
    "for p, thresh in zip(percentiles, thresholds):\n",
    "    is_outlier = reconstruction_errors >= thresh\n",
    "    tp = np.sum((~is_normal) & is_outlier)  \n",
    "    fp = np.sum(is_normal & is_outlier)     \n",
    "    print(f\"For {p}th percentile threshold:\")\n",
    "    print(f\"  tp_{p} = {tp}\")\n",
    "    print(f\"  fp_{p} = {fp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2489cc87",
   "metadata": {},
   "source": [
    "# 2. K-means Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d77a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def load_iris_data(path=Path(\"datasets/iris/iris.csv\")):\n",
    "    df = pd.read_csv(path)\n",
    "    data = df.iloc[:, :-1].values\n",
    "    labels = df['target'].values\n",
    "    return data, labels\n",
    "\n",
    "def print_iris_info(data, labels):\n",
    "    n_samples, n_features = data.shape\n",
    "    n_classes = len(np.unique(labels))\n",
    "    feature_names = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "\n",
    "    print(f\"Number of samples: {n_samples}\")\n",
    "    print(f\"Number of features: {n_features}\")\n",
    "    print(f\"Number of classes: {n_classes}\")\n",
    "    print(f\"Feature names: {feature_names}\")\n",
    "    print(f\"Class distribution:\")\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    for cls, count in zip(unique, counts):\n",
    "        print(f\"  Class {cls}: {count} samples\")\n",
    "\n",
    "def init_centroids_greedy_pp(D,r,l=10):\n",
    "    '''\n",
    "        :param r: (int) number of centroids (clusters)\n",
    "        :param D: (np-array) the data matrix\n",
    "        :param l: (int) number of centroid candidates in each step\n",
    "        :return: (np-array) 'X' the selected centroids from the dataset\n",
    "    '''   \n",
    "    rng =  np.random.default_rng(seed=RANDOM_SEED) # use this random generator to sample the candidates (sampling according to given probabilities can be done via rng.choice(..))\n",
    "    n,d = D.shape\n",
    "\n",
    "    # Your code here\n",
    "\n",
    "    indexes = rng.integers(low=0, high=n, size=r)\n",
    "    X = np.array(D[indexes,:]).T\n",
    "    return X\n",
    "\n",
    "# K-means implementation from the lecture slides\n",
    "def RSS(D,X,Y):\n",
    "    return np.sum((D- Y@X.T)**2)\n",
    "    \n",
    "def getY(labels):\n",
    "    Y = np.eye(max(labels)+1)[labels]\n",
    "    return Y\n",
    "    \n",
    "def update_centroid(D,Y):\n",
    "    cluster_sizes = np.diag(Y.T@Y).copy()\n",
    "    cluster_sizes[cluster_sizes==0]=1\n",
    "    return D.T@Y/cluster_sizes\n",
    "    \n",
    "def update_assignment(D,X):\n",
    "    dist = np.sum((np.expand_dims(D,2) - X)**2,1)\n",
    "    labels = np.argmin(dist,1)\n",
    "    return getY(labels)\n",
    "    \n",
    "def kmeans(D,r, X_init, epsilon=0.00001, t_max=10000):\n",
    "    X = X_init.copy()\n",
    "    Y = update_assignment(D,X)\n",
    "    rss_old = RSS(D,X,Y) +2*epsilon\n",
    "    t=0\n",
    "    \n",
    "    #Looping as long as difference of objective function values is larger than epsilon\n",
    "    while rss_old - RSS(D,X,Y) > epsilon and t < t_max-1:\n",
    "        rss_old = RSS(D,X,Y)\n",
    "        X = update_centroid(D,Y)\n",
    "        Y = update_assignment(D,X)\n",
    "        t+=1\n",
    "    print(t,\"iterations\")\n",
    "    return X,Y\n",
    "\n",
    "\n",
    "data, labels = load_iris_data()\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad0a917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 iterations\n",
      "Mean approximation error: 0.1314\n",
      "Normalized Mutual Information (NMI): 0.7419\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def load_iris_data(path=Path(\"datasets/iris/iris.csv\")):\n",
    "    df = pd.read_csv(path)\n",
    "    data = df.iloc[:, :-1].values\n",
    "    labels = df['target'].values\n",
    "    return data, labels\n",
    "\n",
    "def print_iris_info(data, labels):\n",
    "    n_samples, n_features = data.shape\n",
    "    n_classes = len(np.unique(labels))\n",
    "    feature_names = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "\n",
    "    print(f\"Number of samples: {n_samples}\")\n",
    "    print(f\"Number of features: {n_features}\")\n",
    "    print(f\"Number of classes: {n_classes}\")\n",
    "    print(f\"Feature names: {feature_names}\")\n",
    "    print(f\"Class distribution:\")\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    for cls, count in zip(unique, counts):\n",
    "        print(f\"  Class {cls}: {count} samples\")\n",
    "\n",
    "def init_centroids_greedy_pp(D, r, l=10):\n",
    "    rng = np.random.default_rng(seed=RANDOM_SEED)\n",
    "    n, d = D.shape\n",
    "\n",
    "    # Step 1: Initial random candidates\n",
    "    candidate_idxs = rng.choice(n, size=l, replace=False)\n",
    "    sum_dists = [np.sum(np.linalg.norm(D - D[i], axis=1)**2) for i in candidate_idxs]\n",
    "    best_first_idx = candidate_idxs[np.argmin(sum_dists)]\n",
    "    X = D[best_first_idx].reshape(1, -1)  # First centroid\n",
    "\n",
    "    # Step 2: Greedily select remaining centroids\n",
    "    while X.shape[0] < r:\n",
    "        # Compute distances to the closest centroid for all points\n",
    "        dists = np.min([np.linalg.norm(D - x, axis=1)**2 for x in X], axis=0)\n",
    "        probs = dists / np.sum(dists)\n",
    "        \n",
    "        # Sample l candidates with replacement\n",
    "        candidate_idxs = rng.choice(n, size=l, p=probs, replace=False)\n",
    "        \n",
    "        # Select the candidate that would best reduce total distance\n",
    "        min_total_dist = np.inf\n",
    "        best_idx = None\n",
    "        for idx in candidate_idxs:\n",
    "            new_X = np.vstack([X, D[idx]])\n",
    "            new_dists = np.min([np.linalg.norm(D - x, axis=1)**2 for x in new_X], axis=0)\n",
    "            total_dist = np.sum(new_dists)\n",
    "            if total_dist < min_total_dist:\n",
    "                min_total_dist = total_dist\n",
    "                best_idx = idx\n",
    "        \n",
    "        X = np.vstack([X, D[best_idx]])\n",
    "\n",
    "    return X.T  # shape (d, r)\n",
    "\n",
    "    # Your code here\n",
    "\n",
    "    indexes = rng.integers(low=0, high=n, size=r)\n",
    "    X = np.array(D[indexes,:]).T\n",
    "    return X\n",
    "\n",
    "# K-means implementation from the lecture slides\n",
    "def RSS(D,X,Y):\n",
    "    return np.sum((D- Y@X.T)**2)\n",
    "    \n",
    "def getY(labels):\n",
    "    Y = np.eye(max(labels)+1)[labels]\n",
    "    return Y\n",
    "    \n",
    "def update_centroid(D,Y):\n",
    "    cluster_sizes = np.diag(Y.T@Y).copy()\n",
    "    cluster_sizes[cluster_sizes==0]=1\n",
    "    return D.T@Y/cluster_sizes\n",
    "    \n",
    "def update_assignment(D,X):\n",
    "    dist = np.sum((np.expand_dims(D,2) - X)**2,1)\n",
    "    labels = np.argmin(dist,1)\n",
    "    return getY(labels)\n",
    "    \n",
    "def kmeans(D,r, X_init, epsilon=0.00001, t_max=10000):\n",
    "    X = X_init.copy()\n",
    "    Y = update_assignment(D,X)\n",
    "    rss_old = RSS(D,X,Y) +2*epsilon\n",
    "    t=0\n",
    "    \n",
    "    #Looping as long as difference of objective function values is larger than epsilon\n",
    "    while rss_old - RSS(D,X,Y) > epsilon and t < t_max-1:\n",
    "        rss_old = RSS(D,X,Y)\n",
    "        X = update_centroid(D,Y)\n",
    "        Y = update_assignment(D,X)\n",
    "        t+=1\n",
    "    print(t,\"iterations\")\n",
    "    return X,Y\n",
    "\n",
    "\n",
    "data, labels = load_iris_data()\n",
    "\n",
    "data, labels = load_iris_data()\n",
    "n, d = data.shape\n",
    "r = 3\n",
    "l = 10\n",
    "\n",
    "# Initialize centroids\n",
    "X_init = init_centroids_greedy_pp(data, r, l)\n",
    "\n",
    "# Run k-means\n",
    "X_final, Y_final = kmeans(data, r, X_init)\n",
    "\n",
    "# Recover cluster labels from one-hot Y\n",
    "cluster_labels = np.argmax(Y_final, axis=1)\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "# Mean approximation error\n",
    "approx_error = RSS(data, X_final, Y_final) / (n * d)\n",
    "print(f\"Mean approximation error: {approx_error:.4f}\")\n",
    "\n",
    "# Normalized Mutual Information\n",
    "nmi = normalized_mutual_info_score(labels, cluster_labels)\n",
    "print(f\"Normalized Mutual Information (NMI): {nmi:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b0be9",
   "metadata": {},
   "source": [
    "# 3. Netflix Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8999edd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:59:37.201807Z",
     "start_time": "2025-05-21T12:59:36.986301Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_ratings_data_pandas(data_dir=\"ml-latest-small/\"):\n",
    "    \"\"\"Load data using pandas dataframes.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    assert data_dir.exists(), f\"{data_dir} does not exist\"\n",
    "\n",
    "    return pd.read_csv(data_dir / 'ratings.csv',sep=',')\n",
    "\n",
    "\n",
    "def load_movies_data_pandas(data_dir=\"ml-latest-small/\"):\n",
    "    \"\"\"Load data using pandas dataframes.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    assert data_dir.exists(), f\"{data_dir} does not exist\"\n",
    "    return pd.read_csv(data_dir / 'movies.csv')\n",
    "\n",
    "\n",
    "def filter_data(ratings_data: pd.DataFrame, movies_data: pd.DataFrame):\n",
    "    \"\"\"Filter data. Too little ratings prevent effective use of matrix completion.\"\"\"\n",
    "    ratings_data = ratings_data.pivot(\n",
    "        index='userId',\n",
    "        columns='movieId',\n",
    "        values='rating'\n",
    "    ).fillna(0)\n",
    "\n",
    "    keep_movie = (ratings_data != 0).sum(axis=0) > 100\n",
    "    ratings_data = ratings_data.loc[:, keep_movie]\n",
    "\n",
    "    # Filter movies_data by movieId (columns of ratings_data after filtering)\n",
    "    movies_data = movies_data[movies_data['movieId'].isin(ratings_data.columns)]\n",
    "\n",
    "    keep_user = (ratings_data != 0).sum(axis=1) >= 5\n",
    "    ratings_data = ratings_data.loc[keep_user, :]\n",
    "\n",
    "    return ratings_data, movies_data\n",
    "\n",
    "\n",
    "def print_data_summary(ratings: pd.DataFrame):\n",
    "    n_users = ratings.shape[0]\n",
    "    n_movies = ratings.shape[1]\n",
    "    n_ratings = (ratings != 0).sum().sum()\n",
    "    density = n_ratings / (n_users * n_movies)\n",
    "\n",
    "    print(f\"Dataset Summary\")\n",
    "    print(f\"----------------\")\n",
    "    print(f\"Users: {n_users}\")\n",
    "    print(f\"Movies: {n_movies}\")\n",
    "    print(f\"Total Ratings: {n_ratings}\")\n",
    "    print(f\"Data Density: {density:.4f} (fraction of observed ratings)\")\n",
    "\n",
    "\n",
    "def load_ratings_data(data_dir=\"ml-latest-small/\", print_summary=False):\n",
    "    \"\"\"Load data in numpy format.\"\"\"\n",
    "    ratings, movies = filter_data(\n",
    "        load_ratings_data_pandas(data_dir=data_dir),\n",
    "        load_movies_data_pandas(data_dir=data_dir)\n",
    "    )\n",
    "    if print_summary:\n",
    "        print_data_summary(ratings)\n",
    "    return ratings.to_numpy()\n",
    "\n",
    "\n",
    "def matrix_completion(D, n_features, n_movies, n_users, t_max=100, lambd=0.1):\n",
    "    np.random.seed(0)\n",
    "    X = np.random.normal(size=(n_movies, n_features))\n",
    "    Y = np.random.normal(size=(n_users, n_features))\n",
    "\n",
    "    # Implementation the optimization procedure here\n",
    "    raise NotImplementedError\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e83f2b82e3dccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:59:37.485146Z",
     "start_time": "2025-05-21T12:59:37.387487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary\n",
      "----------------\n",
      "Users: 556\n",
      "Movies: 134\n",
      "Total Ratings: 19694\n",
      "Data Density: 0.2643 (fraction of observed ratings)\n"
     ]
    }
   ],
   "source": [
    "ratings = load_ratings_data(\"datasets/ml-latest-small\", print_summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81460c82",
   "metadata": {},
   "source": [
    "# 4. Image Classification With Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d56288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN Embedding Space Visualization\n",
    "\n",
    "This educational module demonstrates:\n",
    "- ResNet-style architecture with skip connections\n",
    "- Embedding space learning for visualization\n",
    "- Domain transfer between MNIST and Fashion-MNIST\n",
    "- Decision boundary visualization\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Optional, Callable\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration parameters for the model and training.\"\"\"\n",
    "\n",
    "    # Model architecture\n",
    "    embedding_dim: int = 2\n",
    "    num_classes: int = 10\n",
    "\n",
    "    # Training hyperparameters\n",
    "    learning_rate: float = 0.9 \n",
    "    momentum: float = 0.9\n",
    "    weight_decay: float = 5e-4\n",
    "    batch_size: int = 128\n",
    "    epochs: int = 5\n",
    "    dropout_rate_1: float = 0.9\n",
    "    dropout_rate_2: float = 0.9\n",
    "\n",
    "    # Visualization\n",
    "    viz_samples: int = 100\n",
    "    viz_zoom: float = 0.7\n",
    "    grid_resolution: float = 0.1 \n",
    "    \n",
    "    # Paths\n",
    "    checkpoint_dir: Path = Path(\"checkpoint\")\n",
    "    model_filename: str = \"embedding_model.pth\"\n",
    "\n",
    "    @property\n",
    "    def device(self) -> str:\n",
    "        \"\"\"Get the appropriate device for computation.\"\"\"\n",
    "        return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block with skip connections and grouped convolutions.\n",
    "\n",
    "    Implements: output = input + F(input)\n",
    "    where F is a residual function composed of BatchNorm→ReLU→Conv layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, groups: int = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        groups = min(groups, min(in_channels, out_channels))\n",
    "\n",
    "        # Main convolution pathway\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                              padding=\"same\", groups=groups)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size,\n",
    "                              padding=\"same\", groups=min(groups, out_channels))\n",
    "\n",
    "        # Skip connection (identity or dimension adjustment)\n",
    "        self.skip_connection = (\n",
    "            nn.Identity() if in_channels == out_channels\n",
    "            else nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=\"same\")\n",
    "        )\n",
    "\n",
    "        # Pre-activation normalization layers\n",
    "        self.norm1 = nn.BatchNorm2d(in_channels)\n",
    "        self.norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass implementing residual connection.\"\"\"\n",
    "        identity = self.skip_connection(x)\n",
    "\n",
    "        # Residual pathway: BatchNorm → ReLU → Conv → BatchNorm → ReLU → Conv\n",
    "        out = self.conv1(self.relu(self.norm1(x)))\n",
    "        out = self.conv2(self.relu(self.norm2(out)))\n",
    "\n",
    "        return identity + out\n",
    "\n",
    "\n",
    "class EmbeddingNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN that maps input images to low-dimensional embedding space.\n",
    "\n",
    "    Uses global average pooling instead of flattening to reduce overfitting\n",
    "    and make the model robust to different input sizes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim: int, dropout_rate_1: float, dropout_rate_2: float):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial feature extraction\n",
    "        self.initial_conv = nn.Conv2d(1, 32, kernel_size=5, padding=\"same\")\n",
    "        self.initial_norm = nn.BatchNorm2d(32)\n",
    "\n",
    "        # First residual block set (32 channels, groups=2)\n",
    "        self.res_block1 = ResidualBlock(32, 32, kernel_size=3, groups=2)\n",
    "        self.res_block2 = ResidualBlock(32, 32, kernel_size=3, groups=2)\n",
    "\n",
    "        # Spatial downsampling\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.norm_after_pool = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Second residual block set (64 channels, groups=4)\n",
    "        self.res_block3 = ResidualBlock(32, 64, kernel_size=3, groups=4)\n",
    "        self.res_block4 = ResidualBlock(64, 64, kernel_size=3, groups=4)\n",
    "\n",
    "        # Final processing\n",
    "        self.final_norm = nn.BatchNorm1d(64)\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, embedding_dim)\n",
    "\n",
    "        # Regularization\n",
    "        self.dropout1 = nn.Dropout(dropout_rate_1)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate_2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass mapping images to embedding space.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, 1, 28, 28)\n",
    "\n",
    "        Returns:\n",
    "            Embedding tensor of shape (batch_size, embedding_dim)\n",
    "        \"\"\"\n",
    "        out = F.relu(self.initial_norm(self.initial_conv(x)))\n",
    "\n",
    "        # out.shape = ? (tensor shape 1)\n",
    "\n",
    "        # First round of residual blocks\n",
    "        out = self.res_block2(self.res_block1(out))\n",
    "\n",
    "        # out.shape = ? (tensor shape 2)\n",
    "\n",
    "        # Pooling\n",
    "        out = self.norm_after_pool(self.pool(out))\n",
    "\n",
    "        # out.shape = ? (tensor shape 3)\n",
    "\n",
    "        # Second round of residual blocks\n",
    "        out = self.res_block4(self.res_block3(out))\n",
    "\n",
    "        # out.shape = ? (tensor shape 4)\n",
    "\n",
    "        # Global average pooling\n",
    "        out = torch.mean(out, dim=(-1, -2))\n",
    "        out = self.final_norm(out)\n",
    "\n",
    "        # out.shape = ? (tensor shape 5)\n",
    "\n",
    "        # Map to embedding space\n",
    "        out = self.dropout1(out)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    \"\"\"Complete model combining embedding network with classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim: int, num_classes: int, config: Config):\n",
    "        super().__init__()\n",
    "        self.embedding_net = EmbeddingNetwork(\n",
    "            embedding_dim, config.dropout_rate_1, config.dropout_rate_2\n",
    "        )\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes, bias=True)\n",
    "\n",
    "        nn.init.normal_(self.classifier.weight, 0, 0.01)\n",
    "        nn.init.constant_(self.classifier.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass for training and evaluation.\"\"\"\n",
    "        embeddings = self.embedding_net(x)\n",
    "        return self.classifier(embeddings)\n",
    "\n",
    "    def get_embeddings(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Extract embeddings for visualization.\"\"\"\n",
    "        return self.embedding_net(x)\n",
    "\n",
    "    def get_probabilities(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get class probabilities for confidence visualization.\"\"\"\n",
    "        embeddings = self.embedding_net(x)\n",
    "        return F.softmax(self.classifier(embeddings), dim=1)\n",
    "\n",
    "\n",
    "def create_data_loaders(dataset_class, config: Config) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Create training and test data loaders.\n",
    "\n",
    "    Args:\n",
    "        dataset_class: torchvision dataset class (MNIST or FashionMNIST)\n",
    "        config: Configuration object\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_loader, test_loader)\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))  # MNIST standard values\n",
    "    ])\n",
    "\n",
    "    # Training data\n",
    "    train_dataset = dataset_class(root='./data', train=True, download=True, transform=transform)\n",
    "    if config.num_classes < 10:\n",
    "        mask = train_dataset.targets < config.num_classes\n",
    "        train_dataset.targets = train_dataset.targets[mask]\n",
    "        train_dataset.data = train_dataset.data[mask]\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    # Test data\n",
    "    test_dataset = dataset_class(root='./data', train=False, download=True, transform=transform)\n",
    "    if config.num_classes < 10:\n",
    "        mask = test_dataset.targets < config.num_classes\n",
    "        test_dataset.targets = test_dataset.targets[mask]\n",
    "        test_dataset.data = test_dataset.data[mask]\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EpochMetrics:\n",
    "    \"\"\"Container for epoch training/evaluation metrics.\"\"\"\n",
    "    accuracy: float\n",
    "    avg_confidence: float\n",
    "    avg_loss: float\n",
    "    total_samples: int\n",
    "    elapsed_time: Optional[float] = None\n",
    "\n",
    "\n",
    "def compute_batch_metrics(logits: torch.Tensor, targets: torch.Tensor, loss: torch.Tensor) -> Tuple[int, float, int]:\n",
    "    \"\"\"\n",
    "    Compute metrics for a single batch.\n",
    "\n",
    "    Args:\n",
    "        logits: Model output logits\n",
    "        targets: Ground truth labels\n",
    "        loss: Computed loss for the batch\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (correct_predictions, total_confidence, batch_size)\n",
    "    \"\"\"\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "    confidences, predictions = probabilities.max(1)\n",
    "\n",
    "    correct_predictions = predictions.eq(targets).sum().item()\n",
    "    total_confidence = confidences.sum().item()\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    return correct_predictions, total_confidence, batch_size\n",
    "\n",
    "\n",
    "def run_epoch(\n",
    "    model: nn.Module,\n",
    "    criterion,\n",
    "    data_loader: DataLoader,\n",
    "    device: str,\n",
    "    optimizer=None,\n",
    "    is_training: bool = True\n",
    ") -> EpochMetrics:\n",
    "    \"\"\"\n",
    "    Run one epoch of training or evaluation.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        criterion: Loss function\n",
    "        data_loader: Data loader\n",
    "        device: Device to run on\n",
    "        optimizer: Optimizer (required if is_training=True)\n",
    "        is_training: Whether to run in training mode\n",
    "\n",
    "    Returns:\n",
    "        EpochMetrics containing all computed metrics\n",
    "    \"\"\"\n",
    "    if is_training:\n",
    "        if optimizer is None:\n",
    "            raise ValueError(\"Optimizer required for training mode\")\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_confidence = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    context_manager = torch.no_grad() if not is_training else torch.enable_grad()\n",
    "\n",
    "    with context_manager:\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            if is_training:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                print(\"Warning: NaN loss detected\")\n",
    "\n",
    "            if is_training:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Compute batch metrics (always without gradients for metrics)\n",
    "            with torch.no_grad():\n",
    "                batch_correct, batch_confidence, batch_size = compute_batch_metrics(logits, targets, loss)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                total_correct += batch_correct\n",
    "                total_confidence += batch_confidence\n",
    "                total_samples += batch_size\n",
    "\n",
    "    # Calculate final metrics\n",
    "    if total_samples == 0:\n",
    "        print(\"Warning: No samples processed\")\n",
    "        return EpochMetrics(0, 0, float('inf'), 0, time.time() - start_time)\n",
    "\n",
    "    accuracy = 100.0 * total_correct / total_samples\n",
    "    avg_confidence = 100.0 * total_confidence / total_samples\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    return EpochMetrics(\n",
    "        accuracy=accuracy,\n",
    "        avg_confidence=avg_confidence,\n",
    "        avg_loss=avg_loss,\n",
    "        total_samples=total_samples,\n",
    "        elapsed_time=elapsed_time\n",
    "    )\n",
    "\n",
    "\n",
    "def train_epoch(model: nn.Module, criterion, optimizer, data_loader: DataLoader, device: str) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Train model for one epoch.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (accuracy, average_confidence)\n",
    "    \"\"\"\n",
    "    metrics = run_epoch(model, criterion, data_loader, device, optimizer, is_training=True)\n",
    "\n",
    "    print(f'Train - Loss: {metrics.avg_loss:.3f} | '\n",
    "          f'Acc: {metrics.accuracy:.3f}% ({int(metrics.accuracy * metrics.total_samples / 100)}/{metrics.total_samples}) | '\n",
    "          f'Conf: {metrics.avg_confidence:.2f}% | Time: {metrics.elapsed_time:.2f}s')\n",
    "\n",
    "    return metrics.accuracy, metrics.avg_confidence\n",
    "\n",
    "\n",
    "def evaluate_model(model: nn.Module, criterion, data_loader: DataLoader, device: str) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate model on test data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (accuracy, average_confidence)\n",
    "    \"\"\"\n",
    "    metrics = run_epoch(model, criterion, data_loader, device, optimizer=None, is_training=False)\n",
    "\n",
    "    print(f'Test  - Loss: {metrics.avg_loss:.3f} | '\n",
    "          f'Acc: {metrics.accuracy:.3f}% ({int(metrics.accuracy * metrics.total_samples / 100)}/{metrics.total_samples}) | '\n",
    "          f'Conf: {metrics.avg_confidence:.2f}%')\n",
    "\n",
    "    return metrics.accuracy, metrics.avg_confidence\n",
    "\n",
    "\n",
    "def save_model(model: nn.Module, accuracy: float, config: Config) -> None:\n",
    "    \"\"\"Save model checkpoint.\"\"\"\n",
    "    config.checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'accuracy': accuracy,\n",
    "        'config': {\n",
    "            'embedding_dim': config.embedding_dim,\n",
    "            'num_classes': config.num_classes,\n",
    "            'dropout_rate_1': config.dropout_rate_1,\n",
    "            'dropout_rate_2': config.dropout_rate_2,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    save_path = config.checkpoint_dir / config.model_filename\n",
    "    torch.save(checkpoint, save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "\n",
    "def load_model(config: Config) -> EmbeddingClassifier:\n",
    "    \"\"\"Load model from checkpoint.\"\"\"\n",
    "    load_path = config.checkpoint_dir / config.model_filename\n",
    "\n",
    "    model = EmbeddingClassifier(config.embedding_dim, config.num_classes, config)\n",
    "    checkpoint = torch.load(load_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"Model loaded from {load_path}\")\n",
    "    print(f\"Loaded model accuracy: {checkpoint['accuracy']:.2f}%\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_decision_boundary(\n",
    "    model: EmbeddingClassifier,\n",
    "    bounds: Tuple[float, float, float, float],\n",
    "    config: Config,\n",
    "    show_classes: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot decision boundary or confidence map in embedding space.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        bounds: (x_min, x_max, y_min, y_max) for plot region\n",
    "        config: Configuration object\n",
    "        show_classes: If True, show class assignments; if False, show confidence\n",
    "    \"\"\"\n",
    "    x_min, x_max, y_min, y_max = bounds\n",
    "\n",
    "    if not all(np.isfinite([x_min, x_max, y_min, y_max])):\n",
    "        print(\"Warning: Invalid bounds detected, using default range\")\n",
    "        x_min, x_max, y_min, y_max = -10, 10, -10, 10\n",
    "\n",
    "    if x_max <= x_min:\n",
    "        x_max = x_min + 10\n",
    "    if y_max <= y_min:\n",
    "        y_max = y_min + 10\n",
    "\n",
    "    x = np.arange(x_min, x_max, config.grid_resolution, dtype=np.float32)\n",
    "    y = np.arange(y_min, y_max, config.grid_resolution, dtype=np.float32)\n",
    "\n",
    "    if len(x) == 0 or len(y) == 0:\n",
    "        print(\"Warning: Empty grid, adjusting resolution\")\n",
    "        x = np.linspace(x_min, x_max, 50, dtype=np.float32)\n",
    "        y = np.linspace(y_min, y_max, 50, dtype=np.float32)\n",
    "\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "    # Create grid points for evaluation\n",
    "    grid_points = torch.from_numpy(\n",
    "        np.array([xx.ravel(), yy.ravel()]).T\n",
    "    ).float().to(config.device)\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        probabilities = torch.softmax(model.classifier(grid_points), dim=1)\n",
    "        probabilities = probabilities.cpu().numpy()\n",
    "\n",
    "    # Reshape for contour plotting\n",
    "    if show_classes:\n",
    "        class_assignments = probabilities.argmax(axis=1).reshape(xx.shape)\n",
    "        plt.contourf(xx, yy, class_assignments, levels=config.num_classes, cmap='tab10', alpha=0.7)\n",
    "        plt.colorbar(label='Predicted Class')\n",
    "    else:\n",
    "        confidence_map = probabilities.max(axis=1).reshape(xx.shape)\n",
    "        contour = plt.contourf(xx, yy, confidence_map, levels=20, cmap='viridis', alpha=0.7)\n",
    "        plt.clim(0, 1)\n",
    "        plt.colorbar(contour, label='Max Confidence')\n",
    "\n",
    "    plt.axis('equal')\n",
    "\n",
    "\n",
    "def scatter_images_on_embeddings(\n",
    "    images: torch.Tensor,\n",
    "    embeddings: torch.Tensor,\n",
    "    config: Config\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Scatter actual images at their embedding coordinates.\n",
    "\n",
    "    Args:\n",
    "        images: Input images tensor\n",
    "        embeddings: Corresponding embedding coordinates\n",
    "        config: Configuration object\n",
    "    \"\"\"\n",
    "    num_samples = min(images.shape[0], config.viz_samples)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        image = images[i].squeeze().cpu().numpy()\n",
    "        embedding_pos = (embeddings[i, 0].item(), embeddings[i, 1].item())\n",
    "\n",
    "        if not all(np.isfinite(embedding_pos)):\n",
    "            continue\n",
    "\n",
    "        offset_image = OffsetImage(image, cmap=\"gray\", zoom=config.viz_zoom)\n",
    "        annotation_box = AnnotationBbox(\n",
    "            offset_image, embedding_pos, xycoords='data', frameon=False, alpha=0.7\n",
    "        )\n",
    "        plt.gca().add_artist(annotation_box)\n",
    "\n",
    "\n",
    "def visualize_embedding_space(\n",
    "    model: EmbeddingClassifier,\n",
    "    data_loader: DataLoader,\n",
    "    config: Config,\n",
    "    title: str = \"Embedding Space Visualization\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of embedding space.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        data_loader: Data loader for visualization\n",
    "        config: Configuration object\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Get batch of data and embeddings\n",
    "    inputs, _ = next(iter(data_loader))\n",
    "    inputs = inputs.to(config.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.get_embeddings(inputs).cpu()\n",
    "\n",
    "    valid_embeddings = embeddings[torch.isfinite(embeddings).all(dim=1)]\n",
    "\n",
    "    if len(valid_embeddings) == 0:\n",
    "        print(\"Warning: No valid embeddings found, using default bounds\")\n",
    "        bounds = (-10, 10, -10, 10)\n",
    "    else:\n",
    "        margin = 3\n",
    "        x_vals = valid_embeddings[:, 0]\n",
    "        y_vals = valid_embeddings[:, 1]\n",
    "\n",
    "        bounds = (\n",
    "            float(x_vals.min() - margin),\n",
    "            float(x_vals.max() + margin),\n",
    "            float(y_vals.min() - margin),\n",
    "            float(y_vals.max() + margin)\n",
    "        )\n",
    "\n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plot_decision_boundary(model, bounds, config)\n",
    "    scatter_images_on_embeddings(inputs.cpu(), embeddings, config)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Embedding Dimension 1')\n",
    "    plt.ylabel('Embedding Dimension 2')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d90146b-527a-4670-aa59-61a16bf28273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Embedding Space Learning\n",
      "==================================================\n",
      "Using device: cpu\n",
      "\n",
      "Preparing MNIST data...\n",
      "Building model...\n",
      "Total parameters: 63,584\n",
      "\n",
      "Training...\n",
      "\n",
      "Epoch 1/5:\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Train - Loss: nan | Acc: 9.913% (5948/60000) | Conf: nan% | Time: 95.23s\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Test  - Loss: nan | Acc: 9.800% (980/10000) | Conf: nan%\n",
      "\n",
      "Epoch 2/5:\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Train - Loss: nan | Acc: 9.872% (5923/60000) | Conf: nan% | Time: 101.70s\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Test  - Loss: nan | Acc: 9.800% (980/10000) | Conf: nan%\n",
      "\n",
      "Epoch 3/5:\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Train - Loss: nan | Acc: 9.872% (5923/60000) | Conf: nan% | Time: 68.16s\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Test  - Loss: nan | Acc: 9.800% (980/10000) | Conf: nan%\n",
      "\n",
      "Epoch 4/5:\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Train - Loss: nan | Acc: 9.872% (5923/60000) | Conf: nan% | Time: 70.00s\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Test  - Loss: nan | Acc: 9.800% (980/10000) | Conf: nan%\n",
      "\n",
      "Epoch 5/5:\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Train - Loss: nan | Acc: 9.872% (5923/60000) | Conf: nan% | Time: 71.99s\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Test  - Loss: nan | Acc: 9.800% (980/10000) | Conf: nan%\n",
      "Model saved to checkpoint\\embedding_model.pth\n",
      "\n",
      "Visualizing MNIST embeddings...\n",
      "Warning: No valid embeddings found, using default bounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\lib\\site-packages\\matplotlib\\contour.py:1454: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "c:\\ProgramData\\anaconda3\\lib\\site-packages\\matplotlib\\contour.py:1455: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing domain transfer with Fashion-MNIST...\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Warning: NaN loss detected\n",
      "Test  - Loss: nan | Acc: 10.000% (1000/10000) | Conf: nan%\n",
      "Warning: No valid embeddings found, using default bounds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Summary:\n",
      "MNIST Test Accuracy: 9.80%\n",
      "Fashion-MNIST Accuracy: 10.00%\n",
      "Domain Transfer Gap: -0.20%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main training and evaluation pipeline.\"\"\"\n",
    "# Edit configuration here like so\n",
    "config = Config(\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "print(\"CNN Embedding Space Learning\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Using device: {config.device}\")\n",
    "\n",
    "# Create data loaders\n",
    "print(\"\\nPreparing MNIST data...\")\n",
    "mnist_train_loader, mnist_test_loader = create_data_loaders(datasets.MNIST, config)\n",
    "\n",
    "# Create and setup model\n",
    "print(\"Building model...\")\n",
    "model = EmbeddingClassifier(config.embedding_dim, config.num_classes, config)\n",
    "model = model.to(config.device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    momentum=config.momentum,\n",
    "    weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nTraining...\")\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{config.epochs}:')\n",
    "    train_epoch(model, criterion, optimizer, mnist_train_loader, config.device)\n",
    "    test_acc, _ = evaluate_model(model, criterion, mnist_test_loader, config.device)\n",
    "\n",
    "    if test_acc > best_accuracy:\n",
    "        best_accuracy = test_acc\n",
    "\n",
    "# Save model\n",
    "save_model(model, best_accuracy, config)\n",
    "\n",
    "# Visualize MNIST embeddings\n",
    "print(\"\\nVisualizing MNIST embeddings...\")\n",
    "try:\n",
    "    visualize_embedding_space(model, mnist_test_loader, config, \"MNIST Embedding Space\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Visualization error: {e}\")\n",
    "\n",
    "# Domain transfer experiment\n",
    "print(\"\\nTesting domain transfer with Fashion-MNIST...\")\n",
    "fashion_train_loader, fashion_test_loader = create_data_loaders(datasets.FashionMNIST, config)\n",
    "\n",
    "fashion_acc, _ = evaluate_model(model, criterion, fashion_test_loader, config.device)\n",
    "\n",
    "# Visualize Fashion-MNIST embeddings\n",
    "try:\n",
    "    visualize_embedding_space(\n",
    "        model, fashion_test_loader, config,\n",
    "        \"Fashion-MNIST Embeddings (MNIST-trained Model)\"\n",
    "    )\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Visualization error: {e}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nResults Summary:\")\n",
    "print(f\"MNIST Test Accuracy: {best_accuracy:.2f}%\")\n",
    "print(f\"Fashion-MNIST Accuracy: {fashion_acc:.2f}%\")\n",
    "print(f\"Domain Transfer Gap: {best_accuracy - fashion_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
